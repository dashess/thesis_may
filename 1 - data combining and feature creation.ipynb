{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import variation\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select activities from the CSV folder\n",
    "filedir = \".\\\\data\\\\\"\n",
    "rawdir = \".\\\\CSV\\\\\"\n",
    "activities = ['cycling', 'driving', 'jogging', 'sleeping', 'walking']\n",
    "epoch_length = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(filedir+'combined_data'):\n",
    "    os.makedirs(filedir+'combined_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Removed!\n"
     ]
    }
   ],
   "source": [
    "## Data fixes\n",
    "df = pd.read_csv(\".\\\\CSV\\\\static_cycling\\\\Josette_cycling.csv\", skiprows=100,names=[\"datetime\", \"acc_x\", \"acc_y\", \"acc_z\", \"lumin\", \"button\", \"temperature\"])\n",
    "df.drop(columns={'lumin','button'},inplace=True)\n",
    "df.to_csv(\".\\\\CSV\\\\cycling\\\\Josette_cycling_FIX_clean.csv\",index=False)\n",
    "df = pd.read_csv(\".\\\\CSV\\\\jogging\\\\marcia_jogging_clean.csv\", skiprows=100,names=[\"datetime\", \"acc_x\", \"acc_y\", \"acc_z\", \"lumin\", \"button\", \"temperature\"])\n",
    "df.drop(columns={'lumin','button'},inplace=True)\n",
    "df.to_csv(\".\\\\CSV\\\\jogging\\\\marcia_jogging_FIX_clean.csv\",index=False)\n",
    "os.remove(\".\\\\CSV\\\\jogging\\\\marcia_jogging_clean.csv\")\n",
    "print(\"File Removed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes first 100 row of uncleaned csv files and gives them correct column names\n",
    "for i in range(len(activities)):\n",
    "    for filename in os.listdir(rawdir+activities[i]):\n",
    "        if filename[-4:] == '.csv':\n",
    "            if filename[-10:] != '_clean.csv':\n",
    "                df = pd.read_csv(rawdir+activities[i]+'\\\\'+filename,skiprows=100,names=[\"datetime\", \"acc_x\", \"acc_y\", \"acc_z\", \"lumin\", \"button\", \"temperature\"])\n",
    "                df.drop(columns={'lumin','button'},inplace=True)\n",
    "                df.to_csv(rawdir+activities[i]+'\\\\'+filename[:-4]+\"_clean.csv\",index=False)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines each activity data into 1 file\n",
    "for i in range(len(activities)):\n",
    "    main_df = pd.DataFrame()\n",
    "    for filename in os.listdir(rawdir+activities[i]):\n",
    "        if filename[-10:] == '_clean.csv':\n",
    "            df = pd.read_csv(rawdir+activities[i]+'\\\\'+filename)\n",
    "            df = df[:((df.shape[0] // epoch_length) * epoch_length)]\n",
    "            df = df[['acc_x', 'acc_y', 'acc_z']]\n",
    "            df['label'] = activities[i]\n",
    "            main_df = main_df.append(df)\n",
    "        else:\n",
    "            continue\n",
    "    main_df.to_csv(filedir+'combined_data'+\"\\\\\"+activities[i]+\"_combined.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cycling_combined.csv',\n",
       " 'driving_combined.csv',\n",
       " 'jogging_combined.csv',\n",
       " 'sleeping_combined.csv',\n",
       " 'walking_combined.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = os.listdir(filedir+\"combined_data\\\\\")\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling = pd.read_csv(filedir+\"combined_data\\\\\"+combined[0])\n",
    "driving = pd.read_csv(filedir+\"combined_data\\\\\"+combined[1])\n",
    "jogging = pd.read_csv(filedir+\"combined_data\\\\\"+combined[2])\n",
    "sleeping = pd.read_csv(filedir+\"combined_data\\\\\"+combined[3])\n",
    "walking = pd.read_csv(filedir+\"combined_data\\\\\"+combined[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171.1 minutes of cycling\n",
      "230.6 minutes of driving\n",
      "162.8 minutes of jogging\n",
      "15477.1 minutes of sleeping\n",
      "345.3 minutes of walking\n"
     ]
    }
   ],
   "source": [
    "print(cycling.shape[0] / 3600, \"minutes of cycling\")\n",
    "print(driving.shape[0] / 3600, \"minutes of driving\")\n",
    "print(jogging.shape[0] / 3600, \"minutes of jogging\")\n",
    "print(sleeping.shape[0] / 3600, \"minutes of sleeping\")\n",
    "print(walking.shape[0] / 3600, \"minutes of walking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1628"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_samples = int(min([(cycling.shape[0] / 360), (driving.shape[0] / 360), \n",
    "                       (jogging.shape[0] / 360), (sleeping.shape[0] / 360), (walking.shape[0] / 360)]))\n",
    "max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = []\n",
    "labels = []\n",
    "array_svm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(filedir+\"combined_data\\\\\"):\n",
    "    df = pd.read_csv(filedir+\"combined_data\\\\\"+filename)\n",
    "    for i in random.sample(range(0, df.shape[0], 360), max_samples):\n",
    "        arrays.append(df[i:i+360][['acc_x', 'acc_y', 'acc_z']].to_numpy())\n",
    "        labels.append(df['label'].iloc[0])\n",
    "        array_inner = []\n",
    "        enmo = np.sqrt(df[i:i+360][['acc_x']].to_numpy()**2 + df[i:i+360][['acc_y']].to_numpy()**2 + df[i:i+360][['acc_z']].to_numpy()**2)\n",
    "        array_inner.append(np.mean(df[i:i+360][['acc_x']].to_numpy())) ## MEAN\n",
    "        array_inner.append(np.mean(df[i:i+360][['acc_y']].to_numpy()))\n",
    "        array_inner.append(np.mean(df[i:i+360][['acc_z']].to_numpy()))\n",
    "        array_inner.append(np.mean(enmo))\n",
    "        array_inner.append(np.median(df[i:i+360][['acc_x']].to_numpy())) ## MEDIAN\n",
    "        array_inner.append(np.median(df[i:i+360][['acc_y']].to_numpy()))\n",
    "        array_inner.append(np.median(df[i:i+360][['acc_z']].to_numpy()))\n",
    "        array_inner.append(np.median(enmo))\n",
    "        array_inner.append(np.std(df[i:i+360][['acc_x']].to_numpy())) ## STANDARD DEVIATION\n",
    "        array_inner.append(np.std(df[i:i+360][['acc_y']].to_numpy()))\n",
    "        array_inner.append(np.std(df[i:i+360][['acc_z']].to_numpy()))\n",
    "        array_inner.append(np.std(enmo))\n",
    "        array_inner.append(variation(df[i:i+360][['acc_x']].to_numpy())[0]) ## VARIATION\n",
    "        array_inner.append(variation(df[i:i+360][['acc_y']].to_numpy())[0])\n",
    "        array_inner.append(variation(df[i:i+360][['acc_z']].to_numpy())[0])\n",
    "        array_inner.append(variation(enmo)[0])\n",
    "        array_inner.append(np.sqrt(np.mean(df[i:i+360][['acc_x']].to_numpy()**2))) ## ROOT MEAN SQUARE\n",
    "        array_inner.append(np.sqrt(np.mean(df[i:i+360][['acc_y']].to_numpy()**2)))\n",
    "        array_inner.append(np.sqrt(np.mean(df[i:i+360][['acc_z']].to_numpy()**2)))\n",
    "        array_inner.append(np.sqrt(np.mean(enmo**2)))\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_x']].to_numpy(), 5, axis = 0)[0]) ## 5th PERCENTILE\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_y']].to_numpy(), 5, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_z']].to_numpy(), 5, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(enmo, 5, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_x']].to_numpy(), 25, axis = 0)[0]) ## 25th PERCENTILE\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_y']].to_numpy(), 25, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_z']].to_numpy(), 25, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(enmo, 25, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_x']].to_numpy(), 75, axis = 0)[0]) ## 75th PERCENTILE\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_y']].to_numpy(), 75, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_z']].to_numpy(), 75, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(enmo, 75, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_x']].to_numpy(), 95, axis = 0)[0]) ## 95th PERCENTILE\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_y']].to_numpy(), 95, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(df[i:i+360][['acc_z']].to_numpy(), 95, axis = 0)[0])\n",
    "        array_inner.append(np.percentile(enmo, 95, axis = 0)[0])\n",
    "        array_inner.append(np.sum(df[i:i+360][['acc_x']].to_numpy()**2, 0)[0] / df[i:i+360][['acc_x']].to_numpy().size) ## SIGNAL POWER\n",
    "        array_inner.append(np.sum(df[i:i+360][['acc_y']].to_numpy()**2, 0)[0] / df[i:i+360][['acc_y']].to_numpy().size)\n",
    "        array_inner.append(np.sum(df[i:i+360][['acc_z']].to_numpy()**2, 0)[0] / df[i:i+360][['acc_z']].to_numpy().size)\n",
    "        array_inner.append(np.sum(enmo**2, 0)[0] / enmo.size)\n",
    "        array_svm.append(array_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\"cnn_array\": np.array(arrays), \"svm_array\": np.array(array_svm), \"label\":labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data to Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(filedir+'data'):\n",
    "    os.makedirs(filedir+'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(filedir+\"data\\\\data.pickle\",\"wb\")\n",
    "pickle.dump(data_dict, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(filedir+\"data\\\\data.pickle\",\"rb\")\n",
    "data_dict2 = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if saved data == to loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(data_dict[\"cnn_array\"], data_dict2[\"cnn_array\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(data_dict[\"svm_array\"], data_dict2[\"svm_array\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
